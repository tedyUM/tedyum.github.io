---
layout: maininfo
title:  Speech and Language
date:   2022-01-24 09:12:24 +0100
categories: main research lines
---

<img src="{{ site.baseurl }}/assets/images/E002_Fig1_Model-01.png" title="Speech model" alt="Speech model" width="300" align=right style="padding-left:10pt; padding-bottom:10pt"/>

Speaking requires the continuous integration of information as a speech stream evolves. However, temporal cues in speech provide in parallel a rich source of content information. How does the brain exploit this temporal structure to optimally process this type of signal?

In a recent computational model we propose that oscillations can in parallel track temporal regularities to track information as well as exploit temporal variability to extract coding information. This is possible as speech signals that are predictable (in content) tend to be uttered earlier. The brain can use these temporal regularities to extract information about speech content via the timing.

In this research line we investigate the interaction between tracking and coding as in the research line [temporal tracking versus temporal coding](/main/research/lines/2022/01/24/tracking-versus-coding.html) but now specifically applied to temporal information in speech and language.

<br>

{% include publication_post.html datfile="2" link=true %}
